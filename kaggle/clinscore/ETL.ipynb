{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import re\n",
    "import spacy\n",
    "import spacy_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import DocBin\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_chunks(l, n):\n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hal/venvs/deep-learning/lib/python3.8/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.2.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[['696 724']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[['668 693']]\n",
      "[['668 693']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[['203 217']]\n",
      "[['203 217']]\n",
      "[['203 217']]\n",
      "[['203 217']]\n",
      "[['203 217']]\n",
      "[['203 217']]\n",
      "[['203 217']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[['70 91']]\n",
      "[['70 91']]\n",
      "[['70 91'], ['176 183']]\n",
      "[['70 91'], ['176 183']]\n",
      "[['70 91'], ['176 183']]\n",
      "[['70 91'], ['176 183']]\n",
      "[['70 91'], ['176 183']]\n",
      "[['70 91'], ['176 183']]\n",
      "[['70 91'], ['176 183']]\n",
      "[['70 91'], ['176 183']]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[['222 258']]\n",
      "[['222 258']]\n",
      "[['222 258']]\n",
      "[['222 258']]\n",
      "[['222 258']]\n",
      "[['222 258']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">HPI: \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    17yo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">17-year</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    M\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Male</span>\n",
       "</mark>\n",
       " presents with \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    palpitations\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">heart-pounding-OR-heart-racing</span>\n",
       "</mark>\n",
       ". Patient reports \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3-4 months of\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Few-months-duration</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    intermittent episodes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Intermittent-symptoms</span>\n",
       "</mark>\n",
       " of &quot;\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    heart beating/pounding\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">heart-pounding-OR-heart-racing</span>\n",
       "</mark>\n",
       " out of my chest.&quot; 2 days ago during a soccer game had an \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    episode\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Intermittent-symptoms</span>\n",
       "</mark>\n",
       ", but this time had \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    chest pressure\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Chest-pressure</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    felt as if he were going to pass out\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Lightheaded</span>\n",
       "</mark>\n",
       " (did not lose conciousness). Of note patient endorses abusing \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    adderall\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Adderall-use</span>\n",
       "</mark>\n",
       ", primarily to study (1-3 times per week). Before recent soccer game, took \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    adderrall\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Adderall-use</span>\n",
       "</mark>\n",
       " night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \r",
       "</br>PMHx: none\r",
       "</br>Rx: uses friends \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    adderrall\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Adderall-use</span>\n",
       "</mark>\n",
       "\r",
       "</br>FHx: \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mom with &quot;thyroid disease\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Family-history-of-thyroid-disorder</span>\n",
       "</mark>\n",
       ",&quot; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dad with recent heart attcak\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Family-history-of-MI-OR-Family-history-of-myocardial-infarction</span>\n",
       "</mark>\n",
       "\r",
       "</br>All: none\r",
       "</br>Immunizations: up to date\r",
       "</br>SHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 17-year, Span: 5:9\n",
      "Label: Male, Span: 10:11\n",
      "Label: heart-pounding-OR-heart-racing, Span: 26:38\n",
      "Label: Few-months-duration, Span: 56:69\n",
      "Label: Intermittent-symptoms, Span: 70:91\n",
      "Label: heart-pounding-OR-heart-racing, Span: 96:118\n",
      "Label: Intermittent-symptoms, Span: 176:183\n",
      "Label: Chest-pressure, Span: 203:217\n",
      "Label: Lightheaded, Span: 222:258\n",
      "Label: Adderall-use, Span: 321:329\n",
      "Label: Adderall-use, Span: 404:413\n",
      "Label: Adderall-use, Span: 652:661\n",
      "Label: Family-history-of-thyroid-disorder, Span: 668:693\n",
      "Label: Family-history-of-MI-OR-Family-history-of-myocardial-infarction, Span: 696:724\n"
     ]
    }
   ],
   "source": [
    "class spacy_prep:\n",
    "    def __init__(self, feature_desc, location_desc, note_corpus):\n",
    "        self.feature_desc = feature_desc\n",
    "        self.location_desc = location_desc\n",
    "        self.note_corpus = note_corpus\n",
    "        self.nlp = spacy.blank('en')\n",
    "        \n",
    "    def start_prep(self):\n",
    "        location_dict = {}\n",
    "        rels = []\n",
    "        feature_keys = self.feature_desc[:, 1]\n",
    "        \n",
    "        for key in feature_keys:\n",
    "            location_dict[key] = []\n",
    "        \n",
    "        for entry in self.location_desc:\n",
    "            for feat in self.feature_desc:\n",
    "                if entry[0] == feat[0]:\n",
    "                    if entry[1] !='[]':\n",
    "                        stripper = entry[1][0:len(entry[1])-1]\n",
    "                        stripper = stripper[1:]\n",
    "                        #stripper = re.sub(' ', '-', stripper)\n",
    "                        #stripper = re.sub(\"'\", \"\", stripper)\n",
    "                        #stripper = re.split(\";\", stripper)\n",
    "                        \n",
    "                        #stripper = re.split(\"t\", stripper)\n",
    "                        stripper = re.split(\",\", stripper)\n",
    "                        stripper = [[int(s) for s in re.findall(r'\\b\\d+\\b', sentry)] for sentry in stripper]\n",
    "                        #print(stripper)\n",
    "                        #stripper = re.split(\",\" , stripper)\n",
    "                        #stripper = [re.sub(\",\",\"\", ent) for ent in stripper]\n",
    "                        #stripper = [re.split(\";\", entity) for entity in stripper]\n",
    "                        #stripper = [[int(e) for e in entu] for entu in stripper]\n",
    "                        indices = []\n",
    "                        for given_list in stripper:\n",
    "                            for list_entry in given_list:\n",
    "                                #print(list_entry)\n",
    "                                \n",
    "                                indices.append(list_entry)\n",
    "                        indices = list(divide_chunks(indices, 2)) #Paired chunks\n",
    "                        #print(indices)\n",
    "                        note_num = entry[2]\n",
    "                        #print(note_num)\n",
    "                        #indices = np.split(indices, 2)\n",
    "                        \n",
    "                        #print(indices)\n",
    "                        location_dict[feat[1]].append(tuple([note_num, indices]))\n",
    "                        \n",
    "        for feat in self.feature_desc:\n",
    "            for (note_num, indexes) in location_dict[feat[1]]:\n",
    "                for entry in indexes:\n",
    "                    start = entry[0]\n",
    "                    stop = entry[1]\n",
    "                    my_note = self.note_corpus.loc[note_num]\n",
    "                    rels.append([my_note, [start, stop], feat[1]])\n",
    "        return rels\n",
    "    \n",
    "    def training_prep(self):\n",
    "        preproccd_data = self.start_prep()\n",
    "        collective_dict = {'TRAINING_DATA': [], \n",
    "                           'VALIDATION_DATA': []}\n",
    "        \n",
    "        \n",
    "        for note in self.note_corpus.values:\n",
    "            entities = []\n",
    "            for entry in preproccd_data:\n",
    "                \n",
    "                if entry[0] == note:\n",
    "                    #print(\"yes\")\n",
    "                    start = entry[1][0]\n",
    "                    stop = entry[1][1]\n",
    "                    key = entry[2]\n",
    "                    entities.append((start, stop, key))\n",
    "                            \n",
    "            results = [note, {\"entities\": entities}]\n",
    "            if results[1]['entities'] == []:\n",
    "                del results[1]\n",
    "                del results[0]\n",
    "                \n",
    "            #print(results)\n",
    "            collective_dict['TRAINING_DATA'].append(results)\n",
    "            \n",
    "        collective_dict['TRAINING_DATA'] = [x for x in collective_dict['TRAINING_DATA'] if x != []]\n",
    "        \n",
    "        collective_dict['TRAINING_DATA'], collective_dict['VALIDATION_DATA'] = train_test_split(collective_dict['TRAINING_DATA'] \n",
    "                                                                                                , test_size=0.2, random_state=42)\n",
    "        json_string = json.dumps(collective_dict)\n",
    "        \n",
    "        with open('clin_data.json', 'w') as outfile:\n",
    "            outfile.write(json_string)\n",
    "            \n",
    "        return collective_dict\n",
    "    \n",
    "    def create_training(self):\n",
    "        coll_dict = self.training_prep()\n",
    "        TRAIN_DATA = coll_dict['TRAINING_DATA']\n",
    "        db = DocBin()\n",
    "        for text, annot in tqdm(TRAIN_DATA):\n",
    "            doc = self.nlp.make_doc(text)\n",
    "            ents = []\n",
    "    \n",
    "            # create span objects\n",
    "            for start, end, label in annot[\"entities\"]:\n",
    "                span = doc.char_span(start, end, label=label, alignment_mode=\"contract\") \n",
    "    \n",
    "                # skip if the character indices do not map to a valid span\n",
    "                if span is None:\n",
    "                    #print(\"start: {}, end: {}, label: {}\".format(start, end, label))\n",
    "                    print(\"Skipping entity.\")\n",
    "                else:\n",
    "                    #print(\"start: {}, end: {}, label: {}\".format(start, end, label))\n",
    "                    ents.append(span)\n",
    "                    # handle erroneous entity annotations by removing them\n",
    "                    try:\n",
    "                        doc.ents = ents\n",
    "                    except:\n",
    "                        # print(\"BAD SPAN:\", span, \"\\n\")\n",
    "                        ents.pop()\n",
    "            doc.ents = ents\n",
    "    \n",
    "            # pack Doc objects into DocBin\n",
    "            db.add(doc)\n",
    "            \n",
    "        return db\n",
    "    \n",
    "    def create_validation(self):\n",
    "        coll_dict = self.training_prep()\n",
    "        VAL_DATA = coll_dict['VALIDATION_DATA']\n",
    "        db = DocBin()\n",
    "        for text, annot in tqdm(VAL_DATA):\n",
    "            doc = self.nlp.make_doc(text)\n",
    "            ents = []\n",
    "    \n",
    "            # create span objects\n",
    "            for start, end, label in annot[\"entities\"]:\n",
    "                span = doc.char_span(start, end, label=label, alignment_mode=\"contract\") \n",
    "    \n",
    "                # skip if the character indices do not map to a valid span\n",
    "                if span is None:\n",
    "                    #print(\"start: {}, end: {}, label: {}\".format(start, end, label))\n",
    "                    print(\"Skipping entity.\")\n",
    "                else:\n",
    "                    #print(\"start: {}, end: {}, label: {}\".format(start, end, label))\n",
    "                    ents.append(span)\n",
    "                    # handle erroneous entity annotations by removing them\n",
    "                    try:\n",
    "                        doc.ents = ents\n",
    "                    except:\n",
    "                        # print(\"BAD SPAN:\", span, \"\\n\")\n",
    "                        ents.pop()\n",
    "            doc.ents = ents\n",
    "    \n",
    "            # pack Doc objects into DocBin\n",
    "            db.add(doc)\n",
    "            \n",
    "        return db\n",
    "    \n",
    "def prep_sub(notes, feature_dict, test_csv):\n",
    "    test_info = test_csv[['case_num', 'pn_num', 'feature_num']].values\n",
    "    nlp_output = spacy.load(\"./output/model-best\")\n",
    "    entities = []\n",
    "    \n",
    "    for entry in test_info:\n",
    "        rel_case_num = entry[0]\n",
    "        rel_note_num = entry[1]\n",
    "        rel_feat_num = entry[2]\n",
    "        rel_note = notes[rel_note_num][0]\n",
    "        rel_doc = nlp_output(rel_note)\n",
    "        \n",
    "        entity_list = []\n",
    "        \n",
    "        for ent in rel_doc.ents:\n",
    "            span_list = []\n",
    "            if feature_dict[ent.label_]== rel_feat_num:\n",
    "                curr_span = str(ent.start_char)+\" \"+ str(ent.end_char)\n",
    "                span_list.append(curr_span)\n",
    "            if span_list != []:\n",
    "                entity_list.append(span_list)\n",
    "            \n",
    "            \n",
    "            entity_list = [x for x in entity_list if x != []]\n",
    "            n_entity_list = []\n",
    "            for entity in entity_list:\n",
    "                entity = [x for x in entity if x != []]\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "'''    \n",
    "def prep_sub(notes, features_dict, test_csv):\n",
    "    test_info = test_csv[['case_num', 'pn_num', 'feature_num']].values\n",
    "    nlp_output = spacy.load(\"./output/model-best\")\n",
    "    entities = []\n",
    "    \n",
    "    for entry in test_info:\n",
    "        rel_case_num = entry[0]\n",
    "        rel_note_num = entry[1]\n",
    "        rel_feat_num = entry[2]\n",
    "        rel_note = notes[rel_note_num][0]\n",
    "        rel_doc = nlp_output(rel_note)\n",
    "        \n",
    "        entity_list = []\n",
    "        \n",
    "        for ent in rel_doc.ents:\n",
    "            span_list = []\n",
    "            if feature_dict[ent.label_]== rel_feat_num:\n",
    "                curr_span = str(ent.start_char)+\" \"+ str(ent.end_char)\n",
    "                print(curr_span)\n",
    "'''        \n",
    "def load_data():\n",
    "    #Load raw data\n",
    "    feature_frame = pd.read_csv('data/features.csv')\n",
    "    note_frame = pd.read_csv('data/patient_notes.csv')\n",
    "    train_frame = pd.read_csv('data/train.csv')\n",
    "    print(\"Feature frame columns:\\n{}\\nNote frame columns:\\n{}\\nTrain frame columns:\\n{}\\n\\n\".format(feature_frame.columns, note_frame.columns, train_frame.columns))\n",
    "    \n",
    "    note_frame.set_index('pn_num', inplace=True)\n",
    "    note_corpus = note_frame['pn_history']\n",
    "    feature_frame = feature_frame.drop_duplicates('feature_text')\n",
    "    \n",
    "    feature_desc = feature_frame[['feature_num', 'feature_text', 'case_num']].values\n",
    "    location_desc = train_frame[['feature_num', 'location', 'pn_num']].values\n",
    "    \n",
    "    '''\n",
    "    prepper = spacy_prep(feature_desc, location_desc, note_corpus)\n",
    "    \n",
    "    TRAIN_DATA_DOC = prepper.create_training()\n",
    "    TRAIN_DATA_DOC.to_disk(\"./TRAIN_DATA/TRAIN_DATA.spacy\")\n",
    "    \n",
    "    VAL_DATA_DOC = prepper.create_validation()\n",
    "    VAL_DATA_DOC.to_disk(\"./TRAIN_DATA/VAL_DATA.spacy\")\n",
    "    '''\n",
    "    sub_dict = submission(feature_desc, note_corpus)\n",
    "    \n",
    "def tester():\n",
    "    note_frame = pd.read_csv('data/patient_notes.csv')\n",
    "    note_corpus = note_frame[['pn_history', 'pn_num']]\n",
    "    \n",
    "    notes = note_corpus.values\n",
    "    \n",
    "    feature_frame = pd.read_csv('data/features.csv')\n",
    "    feature_desc = feature_frame[['feature_num', 'feature_text', 'case_num']].values\n",
    "    test_csv = pd.read_csv('./data/test.csv')\n",
    "    \n",
    "    feature_tup = []    \n",
    "    for entry in feature_desc:\n",
    "        feature_tup.append((entry[1], entry[0]))\n",
    "    \n",
    "    feature_dict = dict(feature_tup)\n",
    "    entities = prep_sub(notes, feature_dict, test_csv)\n",
    "    \n",
    "    model_test = notes[16][0]\n",
    "    #print(model_test)\n",
    "    \n",
    "    nlp_output = spacy.load(\"output/model-best\")\n",
    "    doc = nlp_output(model_test)\n",
    "    displacy.render(doc, style=\"ent\")\n",
    "    \n",
    "    entity_list = []\n",
    "    for ent in doc.ents:\n",
    "        print(\"Label: {}, Span: {}:{}\".format(ent.label_, ent.start_char, ent.end_char))\n",
    "        entity_list.append([ent.label_, ent.start_char, ent.end_char])\n",
    "        \n",
    "    #sub_tup = submission(feature_desc, note_corpus)\n",
    "        \n",
    "def setup():\n",
    "    tester()\n",
    "    \n",
    "if __name__ ==\"__main__\":\n",
    "    setup()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
